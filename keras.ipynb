{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import pandas\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "data_path = \"../flowers/\"\n",
    "flower_types = os.listdir(data_path)\n",
    "if '.DS_Store' in flower_types:\n",
    "    flower_types.remove('.DS_Store')\n",
    "print(flower_types)\n",
    "\n",
    "data_labels =[]     #list containing all the labels such as daisy, rose..\n",
    "data_set= []        #data set list conataining all images\n",
    "image_names=[]      #list containing image file names\n",
    "size= 100,100\n",
    "\n",
    "for labels in flower_types:\n",
    "    for file in os.listdir(os.path.join(data_path,labels)):\n",
    "        if file.endswith(\"jpg\"):\n",
    "            image_names.append(os.path.join(data_path,labels,file))\n",
    "            data_labels.append(labels)\n",
    "            img = cv2.imread(os.path.join(data_path,labels,file))\n",
    "            img_resize = cv2.resize(img,size)\n",
    "            data_set.append(img_resize)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "merged_dataset = list(zip(data_set, data_labels))  #Merging the images with its associated labels\n",
    "random.shuffle(merged_dataset)                     #shuffling the data set\n",
    "data_set, data_labels = zip(*merged_dataset)\n",
    "\n",
    "#train_data, test_data, train_label, test_label = train_test_split(data_set, data_labels, test_size=0.3,random_state=9,stratify=data_labels)  #dividng the dataset to 70/30 train/test dataset\n",
    "#train_data = np.array(train_data)\n",
    "#train_label = np.array(train_label)\n",
    "# test_data = np.array(test_data)\n",
    "# test_label = np.array(test_label)\n",
    "\n",
    "# label_dummies = pandas.get_dummies(train_label)\n",
    "# train_labelidx =  label_dummies.values.argmax(1)\n",
    "# #pandas.unique(train_labelidx)\n",
    "\n",
    "# test_label_dummies = pandas.get_dummies(test_label)\n",
    "# test_labelidx =  test_label_dummies.values.argmax(1)\n",
    "#pandas.unique(test_labelidx)\n",
    "\n",
    "train_data= np.array(data_set)\n",
    "train_label = np.array(data_labels)\n",
    "label_dummies = pandas.get_dummies(train_label)\n",
    "train_labelidx =  label_dummies.values.argmax(1)\n",
    "\n",
    "folds = list(StratifiedKFold(n_splits=10, shuffle=True, random_state=9).split(train_data, train_labelidx))  #applying 10-fold cv\n",
    "cvscores = []\n",
    "cvloss=[]\n",
    "\n",
    "for j,(train_idx,label_idx)  in enumerate(folds):\n",
    "    \n",
    "    print('\\nFold ',j)\n",
    "    model = keras.Sequential([\n",
    "            keras.layers.Flatten(input_shape=(100,100,3)),\n",
    "            keras.layers.Dense(128, activation=tf.nn.tanh),\n",
    "            keras.layers.Dense(50, activation='relu'),\n",
    "            keras.layers.Dense(5, activation=tf.nn.softmax)\n",
    "        ])\n",
    "\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "                      #scoring=\"cross_val_score\")\n",
    "\n",
    "    History= model.fit(train_data[train_idx], train_labelidx[train_idx], epochs=10,validation_data=(train_data[label_idx], train_labelidx[label_idx]),verbose=1)\n",
    "\n",
    "    score = model.evaluate(train_data[label_idx], train_labelidx[label_idx], batch_size=128,verbose=0)\n",
    "    cvscores.append(score[1] * 100)  #accuracy\n",
    "    cvloss.append(score[0])   #loss\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "print(\"%.2f%%\" % (np.mean(cvloss)))\n",
    "\n",
    "plt.plot(History.history['acc'])\n",
    "plt.plot(History.history['val_acc'])\n",
    "plt.title('Sequential Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(History.history['acc'])\n",
    "plt.plot(History.history['val_acc'])\n",
    "plt.title('Sequential Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
